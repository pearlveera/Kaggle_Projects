{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280fa7cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-16T06:28:44.996455Z",
     "iopub.status.busy": "2025-06-16T06:28:44.996071Z",
     "iopub.status.idle": "2025-06-16T06:31:19.687696Z",
     "shell.execute_reply": "2025-06-16T06:31:19.686776Z"
    },
    "papermill": {
     "duration": 154.697986,
     "end_time": "2025-06-16T06:31:19.690432",
     "exception": false,
     "start_time": "2025-06-16T06:28:44.992446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Train shape: (750000, 10)\n",
      "Test shape: (250000, 9)\n",
      "\n",
      "--- Starting Advanced Feature Engineering ---\n",
      "New features created successfully.\n",
      "\n",
      "--- Starting Preprocessing ---\n",
      "Applying one-hot encoding to: ['Soil Type', 'Crop Type']\n",
      "New training data shape after feature engineering: (750000, 27)\n",
      "Preprocessing complete.\n",
      "\n",
      "--- Starting Model Training ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1823\n",
      "[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.884866\n",
      "[LightGBM] [Info] Start training from score -1.880057\n",
      "[LightGBM] [Info] Start training from score -1.897538\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909121\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094845\n",
      "Model training complete.\n",
      "\n",
      "--- Generating Predictions ---\n",
      "\n",
      "Submission file 'submission.csv' created successfully in /kaggle/working/.\n",
      "Submission file head:\n",
      "       id             Fertilizer Name\n",
      "0  750000          DAP 14-35-14 28-28\n",
      "1  750001     17-17-17 20-20 10-26-26\n",
      "2  750002        20-20 28-28 14-35-14\n",
      "3  750003  14-35-14 17-17-17 10-26-26\n",
      "4  750004     20-20 10-26-26 17-17-17\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Data Loading (Kaggle Environment) ---\n",
    "\n",
    "# Define file paths for the Kaggle environment\n",
    "BASE_PATH = '/kaggle/input/playground-series-s5e6/'\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'train.csv')\n",
    "TEST_PATH = os.path.join(BASE_PATH, 'test.csv')\n",
    "SUBMISSION_PATH = os.path.join(BASE_PATH, 'sample_submission.csv')\n",
    "\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    sample_submission_df = pd.read_csv(SUBMISSION_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Make sure the CSV files are located in '{BASE_PATH}'\")\n",
    "    # Fallback for local testing if needed\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Separate target variable and IDs early on\n",
    "y = train_df['Fertilizer Name']\n",
    "train_ids = train_df['id']\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# Drop unnecessary columns and the target from the training set\n",
    "train_df = train_df.drop(columns=['id', 'Fertilizer Name'])\n",
    "test_df = test_df.drop(columns=['id'])\n",
    "\n",
    "\n",
    "# --- 2. Advanced Feature Engineering ---\n",
    "print(\"\\n--- Starting Advanced Feature Engineering ---\")\n",
    "\n",
    "# Combine train and test sets for consistent feature creation\n",
    "combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# a) Nutrient Ratios and Totals\n",
    "epsilon = 1e-6 # Add a small epsilon to prevent division by zero errors\n",
    "combined_df['N_P_Ratio'] = combined_df['Nitrogen'] / (combined_df['Phosphorous'] + epsilon)\n",
    "combined_df['N_K_Ratio'] = combined_df['Nitrogen'] / (combined_df['Potassium'] + epsilon)\n",
    "combined_df['P_K_Ratio'] = combined_df['Phosphorous'] / (combined_df['Potassium'] + epsilon)\n",
    "combined_df['Total_Nutrients'] = combined_df['Nitrogen'] + combined_df['Phosphorous'] + combined_df['Potassium']\n",
    "\n",
    "# b) Climate Interaction Features (based on agronomy principles)\n",
    "# Vapor Pressure Deficit (VPD) - a better measure of plant stress\n",
    "es = 0.6108 * np.exp((17.27 * combined_df['Temparature']) / (combined_df['Temparature'] + 237.3))\n",
    "ea = (combined_df['Humidity'] / 100) * es\n",
    "combined_df['VPD'] = es - ea\n",
    "\n",
    "# c) Soil-Climate Interactions\n",
    "combined_df['Moisture_Temp_Interaction'] = combined_df['Moisture'] * combined_df['Temparature']\n",
    "combined_df['Humidity_Moisture_Interaction'] = combined_df['Humidity'] * combined_df['Moisture']\n",
    "\n",
    "print(\"New features created successfully.\")\n",
    "\n",
    "\n",
    "# --- 3. Preprocessing (Handling Categorical Features) ---\n",
    "print(\"\\n--- Starting Preprocessing ---\")\n",
    "\n",
    "# **FIX:** Use the correct column names with spaces\n",
    "categorical_features = ['Soil Type', 'Crop Type']\n",
    "print(f\"Applying one-hot encoding to: {categorical_features}\")\n",
    "\n",
    "# Apply One-Hot Encoding to convert strings to numbers\n",
    "combined_df = pd.get_dummies(combined_df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Separate back into training and testing sets\n",
    "X_processed = combined_df.iloc[:len(train_df)]\n",
    "X_test_processed = combined_df.iloc[len(train_df):]\n",
    "\n",
    "print(\"New training data shape after feature engineering:\", X_processed.shape)\n",
    "\n",
    "\n",
    "# Encode the categorical target variable ('Fertilizer Name')\n",
    "target_encoder = LabelEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y)\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Model Training (LightGBM) ---\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(objective='multiclass', random_state=42, n_estimators=500, learning_rate=0.05, num_leaves=31)\n",
    "\n",
    "# Train the model on the entire processed training dataset\n",
    "lgbm.fit(X_processed, y_encoded)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "\n",
    "# --- 5. Prediction and Submission File Generation ---\n",
    "print(\"\\n--- Generating Predictions ---\")\n",
    "\n",
    "# Predict probabilities on the processed test set\n",
    "test_probabilities = lgbm.predict_proba(X_test_processed)\n",
    "\n",
    "# Get the indices of the top 3 predictions for each test sample (for MAP@3)\n",
    "top_3_preds_indices = np.argsort(test_probabilities, axis=1)[:, ::-1][:, :3]\n",
    "\n",
    "# Convert indices back to original fertilizer names\n",
    "top_3_preds_labels = target_encoder.inverse_transform(top_3_preds_indices.flatten()).reshape(top_3_preds_indices.shape)\n",
    "\n",
    "# Format predictions into a single space-delimited string\n",
    "predictions_str = [' '.join(preds) for preds in top_3_preds_labels]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Fertilizer Name': predictions_str\n",
    "})\n",
    "\n",
    "# Save the submission file to the /kaggle/working/ directory\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully in /kaggle/working/.\")\n",
    "print(\"Submission file head:\")\n",
    "print(submission_df.head())\n",
    "print(\"\\nScript finished.\")\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12184666,
     "sourceId": 91717,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 160.203743,
   "end_time": "2025-06-16T06:31:20.611976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-16T06:28:40.408233",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
